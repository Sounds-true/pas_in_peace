–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –≠—Ç–æ **–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è** ‚Äî –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ —Å–ª–æ–∂–Ω–∞—è. –î–∞–≤–∞–π—Ç–µ —Å–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É, –∫–æ—Ç–æ—Ä–∞—è:

1. –ú—è–≥–∫–æ –Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç, –∞ –Ω–µ –∑–∞–ø—Ä–µ—â–∞–µ—Ç
2. –û–±—É—á–∞–µ—Ç –∑–¥–æ—Ä–æ–≤–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
3. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ (—Å–≤–æ–∏ ‚Üí –±—ã–≤—à–µ–º—É, –æ—Ç –±—ã–≤—à–µ–≥–æ ‚Üí –≤–∞–º)

---

## üõ°Ô∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Content Guardian System

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            CONTENT GUARDIAN PIPELINE                    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  User Input (Letter/Message)                           ‚îÇ
‚îÇ         ‚Üì                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Stage 1: Multi-Layer NLP Analysis               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 1. Toxicity Detection                      ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Blame language                        ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Insults/profanity                     ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Aggressive tone                       ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 2. Manipulation Detection                  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Guilt-tripping                        ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Triangulation (involving child)       ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Gaslighting patterns                  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 3. Child-Safety Check (for letters)        ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Parental alienation language          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Negative mentions of other parent     ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Age-inappropriate content             ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ 4. Emotional Tone Analysis                 ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Sentiment (positive/negative/mixed)   ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Intensity                             ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ    - Emotional regulation markers          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚Üì                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Stage 2: LLM-Powered Deep Analysis             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Context understanding                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Nuance detection                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Generate improvement suggestions              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚Üì                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Stage 3: Intervention Strategy Selection       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Low Risk ‚Üí Gentle nudge                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Medium Risk ‚Üí Explain + Suggest rewrite         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  High Risk ‚Üí Strong recommendation + Education   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚Üì                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Stage 4: HITL - User Choice                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚úÖ Accept suggestions                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚úèÔ∏è Edit manually                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚ö†Ô∏è Save as draft (revisit later)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚è≠Ô∏è Proceed anyway (with warning stored)         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚Üì                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Stage 5: Long-term Tracking                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Pattern recognition                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Progress monitoring                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Gentle follow-ups on ignored warnings        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîç NLP Analysis Components

### **1. Toxicity Detection Layers**

```python
from transformers import pipeline
from detoxify import Detoxify
import re

class ToxicityAnalyzer:
    """–ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏"""
    
    def __init__(self):
        # Layer 1: Detoxify (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å)
        self.detoxify = Detoxify('multilingual')
        
        # Layer 2: Perspective API (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –µ—Å—Ç—å –∫–≤–æ—Ç—ã)
        # self.perspective = PerspectiveAPI(api_key=KEY)
        
        # Layer 3: Rule-based –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.blame_patterns = self._load_blame_patterns()
        
    def analyze(self, text: str) -> dict:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏"""
        
        results = {
            "toxicity_score": 0.0,
            "categories": {},
            "flags": [],
            "severity": "safe"
        }
        
        # 1. Detoxify analysis
        detoxify_results = self.detoxify.predict(text)
        results["categories"] = {
            "toxicity": detoxify_results['toxicity'],
            "severe_toxicity": detoxify_results['severe_toxicity'],
            "obscene": detoxify_results['obscene'],
            "threat": detoxify_results['threat'],
            "insult": detoxify_results['insult'],
            "identity_attack": detoxify_results['identity_attack']
        }
        
        # 2. Blame language detection
        blame_score = self._detect_blame_language(text)
        results["categories"]["blame"] = blame_score
        
        # 3. Other parent mention check (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø–∏—Å–µ–º —Ä–µ–±–µ–Ω–∫—É!)
        parent_mention = self._detect_other_parent_mention(text)
        results["categories"]["parent_mention"] = parent_mention
        
        # 4. Calculate overall toxicity
        results["toxicity_score"] = max(
            detoxify_results['toxicity'],
            blame_score,
            parent_mention["score"]
        )
        
        # 5. Determine severity
        if results["toxicity_score"] > 0.7:
            results["severity"] = "high"
        elif results["toxicity_score"] > 0.4:
            results["severity"] = "medium"
        else:
            results["severity"] = "low"
        
        # 6. Generate specific flags
        results["flags"] = self._generate_flags(results)
        
        return results
    
    def _detect_blame_language(self, text: str) -> float:
        """–î–µ—Ç–µ–∫—Ü–∏—è –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —è–∑—ã–∫–∞"""
        blame_keywords = [
            # –†—É—Å—Å–∫–∏–π
            r'\b–æ–Ω–∞ –≤–∏–Ω–æ–≤–∞—Ç–∞\b', r'\b–æ–Ω –≤–∏–Ω–æ–≤–∞—Ç\b',
            r'\b–∏–∑-–∑–∞ –Ω–µ–µ\b', r'\b–∏–∑-–∑–∞ –Ω–µ–≥–æ\b',
            r'\b–æ–Ω–∞ —Ä–∞–∑—Ä—É—à–∏–ª–∞\b', r'\b–æ–Ω —Ä–∞–∑—Ä—É—à–∏–ª\b',
            r'\b–æ–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–∏–ª–∞\b', r'\b–æ–Ω –Ω–∞—Å—Ç—Ä–æ–∏–ª\b',
            r'\b–æ–Ω–∞ —É–∫—Ä–∞–ª–∞\b', r'\b–æ–Ω —É–∫—Ä–∞–ª\b',
            r'\b–æ–Ω–∞ –º–æ–Ω—Å—Ç—Ä\b', r'\b–æ–Ω –º–æ–Ω—Å—Ç—Ä\b',
            r'\b—Ç–≤–∞—Ä—å\b', r'\b—Å—É–∫–∞\b', r'\b—É–±–ª—é–¥–æ–∫\b',
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ–±–≤–∏–Ω–µ–Ω–∏–π
            r'\b–≤—Å–µ–≥–¥–∞ .* (–ø–æ—Ä—Ç–∏—Ç|–º–µ—à–∞–µ—Ç|–≤—Ä–µ–¥–∏—Ç)\b',
            r'\b–Ω–∏–∫–æ–≥–¥–∞ –Ω–µ .* (–¥–∞–µ—Ç|–ø–æ–∑–≤–æ–ª—è–µ—Ç)\b',
        ]
        
        count = 0
        for pattern in blame_keywords:
            if re.search(pattern, text, re.IGNORECASE):
                count += 1
        
        # Normalize to 0-1 scale
        return min(count * 0.3, 1.0)
    
    def _detect_other_parent_mention(self, text: str) -> dict:
        """–î–µ—Ç–µ–∫—Ü–∏—è —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥—Ä—É–≥–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è –≤ –ø–∏—Å—å–º–µ —Ä–µ–±–µ–Ω–∫—É"""
        
        parent_terms = [
            r'\b–º–∞–º–∞\b', r'\b–ø–∞–ø–∞\b', r'\b–º–∞—Ç—å\b', r'\b–æ—Ç–µ—Ü\b',
            r'\b—Ç–≤–æ—è –º–∞–º–∞\b', r'\b—Ç–≤–æ–π –ø–∞–ø–∞\b',
            r'\b–æ–Ω–∞\b', r'\b–æ–Ω\b'  # –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ
        ]
        
        negative_context = [
            r'\b–Ω–µ –¥–∞–µ—Ç\b', r'\b–∑–∞–ø—Ä–µ—â–∞–µ—Ç\b', r'\b–º–µ—à–∞–µ—Ç\b',
            r'\b–ø–ª–æ—Ö–æ\b', r'\b–ø–ª–æ—Ö–∞—è\b', r'\b–ø–ª–æ—Ö–æ–π\b',
            r'\b–ª–∂–µ—Ç\b', r'\b–º–∞–Ω–∏–ø—É–ª–∏—Ä—É–µ—Ç\b'
        ]
        
        mentions = []
        for pattern in parent_terms:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è
                start = max(0, match.start() - 50)
                end = min(len(text), match.end() + 50)
                context = text[start:end]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Å–ª–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
                is_negative = any(
                    re.search(neg, context, re.IGNORECASE) 
                    for neg in negative_context
                )
                
                mentions.append({
                    "term": match.group(),
                    "context": context,
                    "is_negative": is_negative
                })
        
        negative_count = sum(1 for m in mentions if m["is_negative"])
        score = min(negative_count * 0.5, 1.0)
        
        return {
            "score": score,
            "mentions": mentions,
            "has_negative": negative_count > 0
        }
    
    def _generate_flags(self, results: dict) -> list:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–ª–∞–≥–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        flags = []
        
        if results["categories"]["toxicity"] > 0.6:
            flags.append({
                "type": "toxicity",
                "severity": "high",
                "message": "–û–±–Ω–∞—Ä—É–∂–µ–Ω –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π —Ç–æ–Ω"
            })
        
        if results["categories"]["blame"] > 0.4:
            flags.append({
                "type": "blame",
                "severity": "medium",
                "message": "–ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π —è–∑—ã–∫"
            })
        
        if results["categories"]["parent_mention"]["has_negative"]:
            flags.append({
                "type": "parent_mention",
                "severity": "high",
                "message": "–ù–µ–≥–∞—Ç–∏–≤–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –¥—Ä—É–≥–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è (–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–∏—Å—å–º–∞ —Ä–µ–±–µ–Ω–∫—É)"
            })
        
        return flags
```

### **2. Manipulation Detection**

```python
class ManipulationDetector:
    """–î–µ—Ç–µ–∫—Ü–∏—è –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    
    def __init__(self, llm):
        self.llm = llm
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π
        self.patterns = {
            "guilt_tripping": [
                r"–µ—Å–ª–∏ –±—ã —Ç—ã.*—è –±—ã –Ω–µ",
                r"–∏–∑-–∑–∞ —Ç–µ–±—è —è",
                r"—Ç—ã –≤–∏–Ω–æ–≤–∞—Ç —á—Ç–æ",
                r"–ø–æ—Å–º–æ—Ç—Ä–∏ —á—Ç–æ —Ç—ã —Å–æ –º–Ω–æ–π —Å–¥–µ–ª–∞–ª"
            ],
            "triangulation": [
                r"—Å–ø—Ä–æ—Å–∏.*—á—Ç–æ (–æ–Ω|–æ–Ω–∞) –¥—É–º–∞–µ—Ç –æ–±–æ –º–Ω–µ",
                r"—Ä–∞—Å—Å–∫–∞–∂–∏ (–º–∞–º–µ|–ø–∞–ø–µ)",
                r"(–æ–Ω|–æ–Ω–∞) –≥–æ–≤–æ—Ä–∏—Ç —á—Ç–æ —è",
                r"–≤—ã–±–µ—Ä–∏ –º–µ–∂–¥—É"
            ],
            "gaslighting": [
                r"—Ç—ã –ø—Ä–µ—É–≤–µ–ª–∏—á–∏–≤–∞–µ—à—å",
                r"—ç—Ç–æ–≥–æ –Ω–µ –±—ã–ª–æ",
                r"—Ç—ã —Å–ª–∏—à–∫–æ–º —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω",
                r"—Ç—ã –ø–æ–º–Ω–∏—à—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ",
                r"—è –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –≥–æ–≤–æ—Ä–∏–ª"
            ],
            "emotional_blackmail": [
                r"–µ—Å–ª–∏ –Ω–µ.*—Ç–æ —è",
                r"—è —É–º—Ä—É –±–µ–∑",
                r"–ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ –ø—Ä–æ—à—É",
                r"—Ç—ã —Ä–∞–∑—Ä—É—à–∏—à—å"
            ]
        }
    
    def detect(self, text: str, context: str = "letter") -> dict:
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π
        context: "letter" (–∫ —Ä–µ–±–µ–Ω–∫—É) –∏–ª–∏ "message" (–∫ –±—ã–≤—à–µ–º—É)
        """
        
        # Rule-based detection
        detected = []
        for manipulation_type, patterns in self.patterns.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    detected.append(manipulation_type)
                    break
        
        # LLM-enhanced detection –¥–ª—è —Ç–æ–Ω–∫–∏—Ö —Å–ª—É—á–∞–µ–≤
        if detected or context == "letter":
            llm_analysis = self._llm_manipulation_check(text, context)
            detected.extend(llm_analysis["additional_flags"])
        
        return {
            "has_manipulation": len(detected) > 0,
            "types": list(set(detected)),
            "severity": self._calculate_severity(detected),
            "explanation": self._generate_explanation(detected, context)
        }
    
    def _llm_manipulation_check(self, text: str, context: str) -> dict:
        """LLM –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç–æ–Ω–∫–∏—Ö –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π"""
        
        prompt = f"""
        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
        –ö–æ–Ω—Ç–µ–∫—Å—Ç: {'–ø–∏—Å—å–º–æ —Ä–æ–¥–∏—Ç–µ–ª—è —Ä–µ–±–µ–Ω–∫—É' if context == 'letter' else '—Å–æ–æ–±—â–µ–Ω–∏–µ –±—ã–≤—à–µ–º—É –ø–∞—Ä—Ç–Ω–µ—Ä—É'}
        
        –¢–µ–∫—Å—Ç: "{text}"
        
        –ú–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:
        1. Guilt-tripping (–≤—ã–∑—ã–≤–∞–Ω–∏–µ —á—É–≤—Å—Ç–≤–∞ –≤–∏–Ω—ã)
        2. Triangulation (–≤–æ–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–±–µ–Ω–∫–∞ –∫–∞–∫ –ø–æ—Å—Ä–µ–¥–Ω–∏–∫–∞)
        3. Gaslighting (–æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏)
        4. Emotional blackmail (—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —à–∞–Ω—Ç–∞–∂)
        5. Parentification (–ø–µ—Ä–µ–∫–ª–∞–¥—ã–≤–∞–Ω–∏–µ –≤–∑—Ä–æ—Å–ª—ã—Ö –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–µ–π –Ω–∞ —Ä–µ–±–µ–Ω–∫–∞)
        
        –û—Ç–≤–µ—Ç –≤ JSON:
        {{
            "detected_manipulations": ["—Ç–∏–ø1", "—Ç–∏–ø2", ...],
            "confidence": 0.0-1.0,
            "explanation": "–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
            "concerning_phrases": ["—Ñ—Ä–∞–∑–∞1", "—Ñ—Ä–∞–∑–∞2"]
        }}
        """
        
        response = self.llm.generate(
            prompt, 
            response_format="json",
            temperature=0.3  # –Ω–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        )
        
        return response
```

### **3. Child-Safety Validator (–¥–ª—è –ø–∏—Å–µ–º)**

```python
class ChildSafetyValidator:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø–∏—Å—å–º–∞ –ø—Ä–∏–Ω—Ü–∏–ø–∞–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ —Å —Ä–µ–±–µ–Ω–∫–æ–º"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def validate_letter(self, letter_text: str, child_age: int) -> dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∏—Å—å–º–∞ —Ä–µ–±–µ–Ω–∫—É"""
        
        issues = []
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –Ω–µ–≥–∞—Ç–∏–≤–∞ –æ –¥—Ä—É–≥–æ–º —Ä–æ–¥–∏—Ç–µ–ª–µ
        other_parent_check = self._check_other_parent_portrayal(letter_text)
        if other_parent_check["has_issues"]:
            issues.append({
                "category": "other_parent_mention",
                "severity": "critical",
                "details": other_parent_check
            })
        
        # 2. –í–æ–∑—Ä–∞—Å—Ç–Ω–∞—è —É–º–µ—Å—Ç–Ω–æ—Å—Ç—å
        age_check = self._check_age_appropriateness(letter_text, child_age)
        if age_check["concerns"]:
            issues.append({
                "category": "age_inappropriate",
                "severity": "medium",
                "details": age_check
            })
        
        # 3. –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
        emotional_check = self._check_emotional_burden(letter_text)
        if emotional_check["too_heavy"]:
            issues.append({
                "category": "emotional_burden",
                "severity": "high",
                "details": emotional_check
            })
        
        # 4. LLM holistic review
        llm_review = self._llm_safety_review(letter_text, child_age)
        
        return {
            "is_safe": len(issues) == 0 and llm_review["safe"],
            "issues": issues,
            "llm_review": llm_review,
            "recommendations": self._generate_recommendations(issues, llm_review)
        }
    
    def _check_other_parent_portrayal(self, text: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥—Ä—É–≥–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è"""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ToxicityAnalyzer
        analyzer = ToxicityAnalyzer()
        parent_mention = analyzer._detect_other_parent_mention(text)
        
        return {
            "has_issues": parent_mention["has_negative"],
            "mentions": parent_mention["mentions"],
            "guidance": """
            ‚ùå –ò–∑–±–µ–≥–∞–π—Ç–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥—Ä—É–≥–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è.
            
            –ü–æ–º–Ω–∏—Ç–µ: —Ä–µ–±–µ–Ω–æ–∫ –ª—é–±–∏—Ç –æ–±–æ–∏—Ö —Ä–æ–¥–∏—Ç–µ–ª–µ–π. –ö—Ä–∏—Ç–∏–∫–∞ –º–∞–º—ã/–ø–∞–ø—ã 
            —Ä–∞–Ω–∏—Ç —Ä–µ–±–µ–Ω–∫–∞ –∏ —Å–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏.
            
            ‚úÖ –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ —Ñ–æ–∫—É—Å–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞:
            - –í–∞—à–µ–π –ª—é–±–≤–∏ –∫ —Ä–µ–±–µ–Ω–∫—É
            - –û–±—â–∏—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è—Ö
            - –ù–∞–¥–µ–∂–¥–µ –Ω–∞ –±—É–¥—É—â–µ–µ
            - –í–∞—à–µ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –±—ã—Ç—å —Ä—è–¥–æ–º
            """
        }
    
    def _check_emotional_burden(self, text: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ —Ä–µ–±–µ–Ω–∫–∞"""
        
        # –ú–∞—Ä–∫–µ—Ä—ã —á—Ä–µ–∑–º–µ—Ä–Ω–æ–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏
        burden_markers = [
            r"—è —Ç–∞–∫ —Å—Ç—Ä–∞–¥–∞—é",
            r"–º–Ω–µ —Ç–∞–∫ –ø–ª–æ—Ö–æ –±–µ–∑ —Ç–µ–±—è",
            r"—è –Ω–µ –º–æ–≥—É –∂–∏—Ç—å",
            r"—Ç—ã –º–æ—è –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è",
            r"—Ç–æ–ª—å–∫–æ —Ç—ã –º–µ–Ω—è –ø–æ–Ω–∏–º–∞–µ—à—å",
            r"—è –¥–µ–ª–∞—é –≤—Å–µ —Ä–∞–¥–∏ —Ç–µ–±—è",
            r"–µ—Å–ª–∏ –±—ã –Ω–µ —Ç—ã, —è –±—ã"
        ]
        
        found_markers = []
        for marker in burden_markers:
            if re.search(marker, text, re.IGNORECASE):
                found_markers.append(marker)
        
        return {
            "too_heavy": len(found_markers) > 2,
            "markers": found_markers,
            "explanation": """
            –ü–∏—Å—å–º–æ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–∑–¥–∞—Ç—å —É —Ä–µ–±–µ–Ω–∫–∞ 
            —á—É–≤—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –≤–∞—à–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ.
            
            –≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è "parentification" ‚Äî –∫–æ–≥–¥–∞ —Ä–µ–±–µ–Ω–æ–∫ —á—É–≤—Å—Ç–≤—É–µ—Ç 
            —Å–µ–±—è –æ–±—è–∑–∞–Ω–Ω—ã–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ä–æ–¥–∏—Ç–µ–ª—è.
            
            –õ—É—á—à–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å, —á—Ç–æ –≤—ã —Å–ø—Ä–∞–≤–ª—è–µ—Ç–µ—Å—å –∏ –≥–æ—Ç–æ–≤—ã –±—ã—Ç—å –æ–ø–æ—Ä–æ–π 
            –¥–ª—è —Ä–µ–±–µ–Ω–∫–∞, –∞ –Ω–µ –Ω–∞–æ–±–æ—Ä–æ—Ç.
            """
        }
    
    def _llm_safety_review(self, text: str, child_age: int) -> dict:
        """–•–æ–ª–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —á–µ—Ä–µ–∑ LLM"""
        
        prompt = f"""
        –¢—ã ‚Äî –¥–µ—Ç—Å–∫–∏–π –ø—Å–∏—Ö–æ–ª–æ–≥, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Ä–∞–∑–≤–æ–¥–∞–º –∏ –æ—Ç—á—É–∂–¥–µ–Ω–∏—é —Ä–æ–¥–∏—Ç–µ–ª–µ–π.
        
        –†–æ–¥–∏—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª –ø–∏—Å—å–º–æ —Ä–µ–±–µ–Ω–∫—É (–≤–æ–∑—Ä–∞—Å—Ç: {child_age} –ª–µ—Ç).
        –û—Ü–µ–Ω–∏, –±–µ–∑–æ–ø–∞—Å–Ω–æ –ª–∏ —ç—Ç–æ –ø–∏—Å—å–º–æ –¥–ª—è —Ä–µ–±–µ–Ω–∫–∞.
        
        –ü–∏—Å—å–º–æ:
        "{text}"
        
        –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏:
        1. –ù–µ—Ç –ª–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥—Ä—É–≥–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è?
        2. –ù–µ —Å–æ–∑–¥–∞–µ—Ç –ª–∏ –ø–∏—Å—å–º–æ –∫–æ–Ω—Ñ–ª–∏–∫—Ç –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏?
        3. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º—É –≤–æ–∑—Ä–∞—Å—Ç—É —Ä–µ–±–µ–Ω–∫–∞?
        4. –ù–µ –ø–µ—Ä–µ–∫–ª–∞–¥—ã–≤–∞–µ—Ç –ª–∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ —Å—á–∞—Å—Ç—å–µ —Ä–æ–¥–∏—Ç–µ–ª—è –Ω–∞ —Ä–µ–±–µ–Ω–∫–∞?
        5. –§–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –ª–∏ –Ω–∞ –ª—é–±–≤–∏ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–µ —Ä–µ–±–µ–Ω–∫–∞?
        
        –û—Ç–≤–µ—Ç –≤ JSON:
        {{
            "safe": true/false,
            "concerns": ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2", ...],
            "positive_aspects": ["—á—Ç–æ —Ö–æ—Ä–æ—à–æ1", "—á—Ç–æ —Ö–æ—Ä–æ—à–æ2", ...],
            "suggestions": ["–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ1", "—É–ª—É—á—à–µ–Ω–∏–µ2", ...],
            "overall_tone": "loving/neutral/concerning"
        }}
        """
        
        return self.llm.generate(prompt, response_format="json")
```

---

## üé≠ Guardian Agent (Multi-Agent Architecture)

```python
class ContentGuardianAgent:
    """–ì–ª–∞–≤–Ω—ã–π –∞–≥–µ–Ω—Ç-—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    
    def __init__(self):
        self.toxicity_analyzer = ToxicityAnalyzer()
        self.manipulation_detector = ManipulationDetector(llm)
        self.child_safety_validator = ChildSafetyValidator(llm)
        self.kag = KAGClient()  # –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
    
    def review_letter(
        self, 
        user_id: str,
        letter_text: str, 
        child_age: int,
        context: dict
    ) -> dict:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–∏—Å—å–º–∞ —Ä–µ–±–µ–Ω–∫—É"""
        
        # 1. –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏
        toxicity = self.toxicity_analyzer.analyze(letter_text)
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π
        manipulation = self.manipulation_detector.detect(
            letter_text, 
            context="letter"
        )
        
        # 3. Child-safety validation
        safety = self.child_safety_validator.validate_letter(
            letter_text, 
            child_age
        )
        
        # 4. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞
        intervention = self._determine_intervention_strategy(
            toxicity, 
            manipulation, 
            safety
        )
        
        # 5. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self._track_patterns(user_id, {
            "toxicity": toxicity,
            "manipulation": manipulation,
            "safety": safety,
            "intervention": intervention
        })
        
        return {
            "analysis": {
                "toxicity": toxicity,
                "manipulation": manipulation,
                "safety": safety
            },
            "intervention": intervention,
            "rewritten_suggestions": self._generate_rewrites(
                letter_text, 
                toxicity, 
                manipulation, 
                safety
            )
        }
    
    def review_message_to_ex(
        self, 
        user_id: str,
        message_text: str
    ) -> dict:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –±—ã–≤—à–µ–º—É –ø–∞—Ä—Ç–Ω–µ—Ä—É"""
        
        # –ü–æ—Ö–æ–∂–∏–π pipeline, –Ω–æ –¥—Ä—É–≥–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
        toxicity = self.toxicity_analyzer.analyze(message_text)
        manipulation = self.manipulation_detector.detect(
            message_text, 
            context="message"
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ BIFF (Brief, Informative, Friendly, Firm)
        biff_check = self._check_biff_compliance(message_text)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —ç—Å–∫–∞–ª–∞—Ü–∏—é –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞
        escalation_risk = self._assess_escalation_risk(message_text)
        
        intervention = self._determine_intervention_strategy(
            toxicity, 
            manipulation, 
            {"biff": biff_check, "escalation": escalation_risk}
        )
        
        return {
            "analysis": {
                "toxicity": toxicity,
                "manipulation": manipulation,
                "biff_compliance": biff_check,
                "escalation_risk": escalation_risk
            },
            "intervention": intervention,
            "rewritten_suggestions": self._generate_biff_rewrite(message_text)
        }
    
    def analyze_incoming_message(
        self, 
        user_id: str,
        message_text: str,
        sender: str = "ex_partner"
    ) -> dict:
        """–ê–Ω–∞–ª–∏–∑ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –±—ã–≤—à–µ–≥–æ –ø–∞—Ä—Ç–Ω–µ—Ä–∞"""
        
        # –ü–æ–º–æ—á—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏
        toxicity = self.toxicity_analyzer.analyze(message_text)
        manipulation = self.manipulation_detector.detect(
            message_text, 
            context="message"
        )
        
        # LLM breakdown –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã—Ö —Ç–µ—Ö–Ω–∏–∫
        breakdown = self._explain_manipulation_tactics(
            message_text,
            manipulation
        )
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–∞–∫ –æ—Ç–≤–µ—Ç–∏—Ç—å
        response_guidance = self._suggest_response_strategy(
            message_text,
            toxicity,
            manipulation
        )
        
        return {
            "sender": sender,
            "analysis": {
                "toxicity": toxicity,
                "manipulation": manipulation
            },
            "breakdown": breakdown,
            "response_guidance": response_guidance
        }
    
    def _determine_intervention_strategy(
        self, 
        toxicity: dict, 
        manipulation: dict, 
        safety: dict
    ) -> dict:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞"""
        
        # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ risk score
        risk_score = max(
            toxicity.get("toxicity_score", 0),
            manipulation.get("severity", 0),
            0 if safety.get("is_safe", True) else 0.8
        )
        
        if risk_score < 0.3:
            return {
                "level": "none",
                "action": "proceed",
                "message": "‚úÖ –ü–∏—Å—å–º–æ –≤—ã–≥–ª—è–¥–∏—Ç —Ö–æ—Ä–æ—à–æ!"
            }
        
        elif risk_score < 0.6:
            return {
                "level": "gentle_nudge",
                "action": "suggest",
                "message": self._craft_gentle_feedback(
                    toxicity, manipulation, safety
                ),
                "allow_proceed": True
            }
        
        else:
            return {
                "level": "strong_recommendation",
                "action": "recommend_rewrite",
                "message": self._craft_strong_feedback(
                    toxicity, manipulation, safety
                ),
                "allow_proceed": True,  # –≤—Å–µ–≥–¥–∞ –ø–æ–∑–≤–æ–ª—è–µ–º, –Ω–æ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
                "flag_for_followup": True  # –≤–µ—Ä–Ω—É—Ç—å—Å—è –ø–æ–∑–∂–µ
            }
    
    def _craft_gentle_feedback(self, toxicity, manipulation, safety) -> str:
        """–ú—è–≥–∫–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å"""
        
        feedback = "üí° –ù–µ–±–æ–ª—å—à–æ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ:\n\n"
        
        if toxicity["toxicity_score"] > 0.3:
            feedback += "–ó–∞–º–µ—Ç–∏–ª –Ω–µ–º–Ω–æ–≥–æ –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω—ã–π —Ç–æ–Ω. "
            feedback += "–í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞—Ç—å —á—É—Ç—å –º—è–≥—á–µ?\n\n"
        
        if safety and not safety.get("is_safe"):
            for issue in safety.get("issues", []):
                if issue["category"] == "other_parent_mention":
                    feedback += """
                    –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ: –≤ –ø–∏—Å—å–º–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –¥—Ä—É–≥–æ–π —Ä–æ–¥–∏—Ç–µ–ª—å 
                    –Ω–µ –≤ —Å–∞–º–æ–º –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–º –∫–ª—é—á–µ. 
                    
                    –ü–æ–º–Ω–∏—Ç–µ, —Ä–µ–±–µ–Ω–æ–∫ –ª—é–±–∏—Ç –æ–±–æ–∏—Ö. –õ—É—á—à–µ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è 
                    —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–∞—à–µ–π —Å–≤—è–∑–∏ —Å –Ω–∏–º/–Ω–µ–π.
                    """
        
        feedback += "\n\n –•–æ—Ç–∏—Ç–µ, —á—Ç–æ–±—ã —è –ø—Ä–µ–¥–ª–æ–∂–∏–ª –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏?"
        
        return feedback
    
    def _craft_strong_feedback(self, toxicity, manipulation, safety) -> str:
        """–°–µ—Ä—å–µ–∑–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å"""
        
        feedback = "‚ö†Ô∏è –í–∞–∂–Ω–æ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ:\n\n"
        
        if safety and not safety["is_safe"]:
            feedback += """
            –≠—Ç–æ –ø–∏—Å—å–º–æ –º–æ–∂–µ—Ç –Ω–µ–ø—Ä–µ–¥–Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –Ω–∞–≤—Ä–µ–¥–∏—Ç—å —Ä–µ–±–µ–Ω–∫—É:
            
            """
            
            for issue in safety["issues"]:
                feedback += f"‚Ä¢ {issue['details'].get('explanation', '')}\n\n"
        
        feedback += """
        –Ø –ø–æ–Ω–∏–º–∞—é, —á—Ç–æ –≤—ã –∏—Å–ø—ã—Ç—ã–≤–∞–µ—Ç–µ —Å–∏–ª—å–Ω—ã–µ —ç–º–æ—Ü–∏–∏. –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ.
        
        –ù–æ –¥–∞–≤–∞–π—Ç–µ –≤–º–µ—Å—Ç–µ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞–µ–º –ø–∏—Å—å–º–æ —Ç–∞–∫, —á—Ç–æ–±—ã:
        ‚úÖ –†–µ–±–µ–Ω–æ–∫ –ø–æ—á—É–≤—Å—Ç–≤–æ–≤–∞–ª –≤–∞—à—É –ª—é–±–æ–≤—å
        ‚úÖ –ù–µ –≤–æ–∑–Ω–∏–∫ –∫–æ–Ω—Ñ–ª–∏–∫—Ç –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏
        ‚úÖ –°–ª–æ–≤–∞ –∏—Å—Ü–µ–ª—è–ª–∏, –∞ –Ω–µ —Ä–∞–Ω–∏–ª–∏
        
        –≠—Ç–æ –ø–∏—Å—å–º–æ —Ä–µ–±–µ–Ω–æ–∫ –º–æ–∂–µ—Ç –ø—Ä–æ—á–∏—Ç–∞—Ç—å —á–µ—Ä–µ–∑ –≥–æ–¥—ã. –ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ, 
        —á—Ç–æ–±—ã –æ–Ω/–æ–Ω–∞ —É–≤–∏–¥–µ–ª –≤ –Ω–µ–º?
        """
        
        return feedback
    
    def _generate_rewrites(
        self, 
        original_text: str,
        toxicity: dict,
        manipulation: dict,
        safety: dict
    ) -> list:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –ø–∏—Å—å–º–∞"""
        
        issues_summary = self._summarize_issues(toxicity, manipulation, safety)
        
        prompt = f"""
        –ò—Å—Ö–æ–¥–Ω–æ–µ –ø–∏—Å—å–º–æ —Ä–æ–¥–∏—Ç–µ–ª—è —Ä–µ–±–µ–Ω–∫—É:
        "{original_text}"
        
        –ü—Ä–æ–±–ª–µ–º—ã:
        {issues_summary}
        
        –ü–µ—Ä–µ–ø–∏—à–∏ –ø–∏—Å—å–º–æ, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –∏ —ç–º–æ—Ü–∏–∏ —Ä–æ–¥–∏—Ç–µ–ª—è, –Ω–æ:
        1. –£–±–µ—Ä–∏ –ª—é–±—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –¥—Ä—É–≥–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è (–¥–∞–∂–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ)
        2. –°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –ª—é–±–≤–∏ –∫ —Ä–µ–±–µ–Ω–∫—É
        3. –ò–∑–±–µ–≥–∞–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏ (–Ω–µ "—è —Å—Ç—Ä–∞–¥–∞—é –±–µ–∑ —Ç–µ–±—è")
        4. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–µ–ø–ª—ã–π, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π —Ç–æ–Ω
        5. –ü–æ–∫–∞–∂–∏, —á—Ç–æ —Ä–æ–¥–∏—Ç–µ–ª—å ‚Äî –Ω–∞–¥–µ–∂–Ω–∞—è –æ–ø–æ—Ä–∞, –∞ –Ω–µ –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫–µ
        
        –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 2 –≤–∞—Ä–∏–∞–Ω—Ç–∞:
        1. –ö–æ—Ä–æ—Ç–∫–∞—è –≤–µ—Ä—Å–∏—è (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
        2. –†–∞–∑–≤–µ—Ä–Ω—É—Ç–∞—è –≤–µ—Ä—Å–∏—è (–∞–±–∑–∞—Ü)
        
        JSON:
        {{
            "short_version": "—Ç–µ–∫—Å—Ç",
            "long_version": "—Ç–µ–∫—Å—Ç",
            "key_changes": ["—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–∏ 1", "—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–∏ 2"]
        }}
        """
        
        suggestions = self.llm.generate(prompt, response_format="json")
        return suggestions
```

---

## üéØ HITL Workflow (–ú—è–≥–∫–æ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ)

```python
# –í BESSER Agent –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

@write_letter_state.body
def review_draft(session):
    """–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª –ø–∏—Å—å–º–æ"""
    
    draft = session.memory.get("draft")
    child_age = session.memory.get("child_age")
    
    # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Guardian Agent
    guardian = ContentGuardianAgent()
    review = guardian.review_letter(
        user_id=session.user_id,
        letter_text=draft,
        child_age=child_age,
        context=session.memory.get_all()
    )
    
    intervention = review["intervention"]
    
    if intervention["level"] == "none":
        # –í—Å–µ —Ö–æ—Ä–æ—à–æ
        session.reply(intervention["message"])
        session.reply("""
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–∏—Å—å–º–æ?
        1. ‚úÖ –î–∞, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å
        2. ‚úèÔ∏è –•–æ—á—É –µ—â–µ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å
        """)
        return save_letter_state
    
    elif intervention["level"] == "gentle_nudge":
        # –ú—è–≥–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        session.reply(intervention["message"])
        
        # –ü–æ–∫–∞–∑–∞—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
        suggestions = review["rewritten_suggestions"]
        session.reply(f"""
        –ü—Ä–µ–¥–ª–∞–≥–∞—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É:
        
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        {suggestions["short_version"]}
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        
        –ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å:
        {chr(10).join(f"‚Ä¢ {change}" for change in suggestions["key_changes"])}
        
        –í—ã–±–µ—Ä–∏—Ç–µ:
        1. ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ—é –≤–µ—Ä—Å–∏—é
        2. üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—É—é
        3. ‚úèÔ∏è –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–∞–º–æ–º—É
        4. üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ —á–µ—Ä–Ω–æ–≤–∏–∫ (–≤–µ—Ä–Ω—É—Ç—å—Å—è –ø–æ–∑–∂–µ)
        """)
        
        session.memory.set("review_suggestions", suggestions)
        return letter_decision_state
    
    else:  # strong_recommendation
        # –°–µ—Ä—å–µ–∑–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞
        session.reply(intervention["message"])
        
        # –ü–æ–∫–∞–∑–∞—Ç—å –æ–±–µ –≤–µ—Ä—Å–∏–∏ —Ä—è–¥–æ–º
        suggestions = review["rewritten_suggestions"]
        session.reply(f"""
        ‚îå‚îÄ –ò–°–•–û–î–ù–ê–Ø –í–ï–†–°–ò–Ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        {draft}
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        
        ‚îå‚îÄ –ü–†–ï–î–õ–û–ñ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        {suggestions["long_version"]}
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        
        –Ø –Ω–∞—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Ç–æ—Ä—É—é –≤–µ—Ä—Å–∏—é.
        
        –ù–æ —Ä–µ—à–µ–Ω–∏–µ –∑–∞ –≤–∞–º–∏:
        1. üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
        2. ‚úèÔ∏è –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—É—é —Å –º–æ–µ–π –ø–æ–º–æ—â—å—é
        3. üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—É—é –∫–∞–∫ —á–µ—Ä–Ω–æ–≤–∏–∫
        4. ‚ö†Ô∏è –í—Å–µ —Ä–∞–≤–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—É—é (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        """)
        
        # –ï—Å–ª–∏ –≤—ã–±–µ—Ä–µ—Ç #4, –ø–æ–º–µ—Ç–∏—Ç—å –¥–ª—è follow-up
        if intervention.get("flag_for_followup"):
            session.memory.set("flagged_letter_id", draft_id)
        
        return letter_decision_state


@letter_decision_state.body
def handle_decision(session):
    choice = session.message
    
    if "—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—É—é" in choice or choice == "1":
        # –ü—Ä–∏–Ω—è–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        suggestions = session.memory.get("review_suggestions")
        final_text = suggestions["long_version"]
        
        session.reply("‚úÖ –û—Ç–ª–∏—á–Ω—ã–π –≤—ã–±–æ—Ä! –≠—Ç–æ –ø–∏—Å—å–º–æ –±—É–¥–µ—Ç –∏—Å—Ü–µ–ª—è—é—â–∏–º –¥–ª—è —Ä–µ–±–µ–Ω–∫–∞.")
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å –º–µ—Ç–∫–æ–π "reviewed_and_improved"
        save_letter(session.user_id, final_text, metadata={
            "guardian_review": "passed_with_improvements",
            "original_had_issues": True
        })
        
    elif "–∏—Å—Ö–æ–¥–Ω—É—é" in choice and "—Ä–∞–≤–Ω–æ" in choice:
        # –ü—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        original = session.memory.get("draft")
        
        session.reply("""
        –•–æ—Ä–æ—à–æ, —è —Å–æ—Ö—Ä–∞–Ω—é –≤–∞—à –≤–∞—Ä–∏–∞–Ω—Ç.
        
        –ù–æ –ø–æ–º–Ω–∏—Ç–µ: —ç—Ç–æ –ø–∏—Å—å–º–æ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–æ –¥–ª—è —Ä–µ–±–µ–Ω–∫–∞, –∫–æ—Ç–æ—Ä—ã–π 
        –º–æ–∂–µ—Ç –ø—Ä–æ—á–∏—Ç–∞—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ –≥–æ–¥—ã. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç 
        –≤–∞—à—É –ª—é–±–æ–≤—å, –∞ –Ω–µ –±–æ–ª—å.
        
        –í–æ–∑–º–æ–∂–Ω–æ, —á–µ—Ä–µ–∑ –∫–∞–∫–æ–µ-—Ç–æ –≤—Ä–µ–º—è –≤—ã –∑–∞—Ö–æ—Ç–∏—Ç–µ –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ –Ω–µ–º—É?
        """)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å warning flag
        letter_id = save_letter(session.user_id, original, metadata={
            "guardian_review": "warning_ignored",
            "needs_followup": True,
            "followup_date": datetime.now() + timedelta(days=7)
        })
        
        # –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å follow-up
        schedule_followup(session.user_id, letter_id, days=7)
    
    elif "—á–µ—Ä–Ω–æ–≤–∏–∫" in choice:
        # –û—Ç–ª–æ–∂–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ
        draft_id = save_draft(session.user_id, session.memory.get("draft"))
        
        session.reply("""
        üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–∫ —á–µ—Ä–Ω–æ–≤–∏–∫.
        
        –•–æ—Ä–æ—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–∞—Ç—å —Å–µ–±–µ –≤—Ä–µ–º—è –ø–æ–¥—É–º–∞—Ç—å.
        –ò–Ω–æ–≥–¥–∞ —ç–º–æ—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –æ—Å—Ç—ã—Ç—å, —á—Ç–æ–±—ã —Å–ª–æ–≤–∞ —Å—Ç–∞–ª–∏ –∏—Å—Ü–µ–ª—è—é—â–∏–º–∏.
        
        –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ —á–µ—Ä–Ω–æ–≤–∏–∫–∞–º: /drafts
        """)
```

---

## üîÑ Follow-up System (–≤–æ–∑–≤—Ä–∞—Ç –∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º –ø–∏—Å—å–º–∞–º)

```python
class FollowUpManager:
    """–°–∏—Å—Ç–µ–º–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ –∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º –ø–∏—Å—å–º–∞–º"""
    
    def __init__(self, kag_client):
        self.kag = kag_client
    
    def schedule_followup(
        self, 
        user_id: str, 
        letter_id: str, 
        days: int = 7
    ):
        """–ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –≤–æ–∑–≤—Ä–∞—Ç –∫ –ø–∏—Å—å–º—É"""
        
        self.kag.create_node(
            type="FollowUp",
            properties={
                "user_id": user_id,
                "letter_id": letter_id,
                "scheduled_date": datetime.now() + timedelta(days=days),
                "reason": "warning_ignored",
                "status": "pending"
            }
        )
    
    def check_due_followups(self, user_id: str) -> list:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã–µ follow-ups"""
        
        followups = self.kag.query(f"""
        MATCH (f:FollowUp)-[:REFERS_TO]->(l:Letter)
        WHERE f.user_id = '{user_id}'
        AND f.scheduled_date <= datetime()
        AND f.status = 'pending'
        RETURN f, l
        """)
        
        return followups
    
    def initiate_followup_conversation(
        self, 
        session, 
        letter_id: str
    ):
        """–ò–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –æ –ø—Ä–æ–±–ª–µ–º–Ω–æ–º –ø–∏—Å—å–º–µ"""
        
        # –ü–æ–ª—É—á–∏—Ç—å –ø–∏—Å—å–º–æ
        letter = self.kag.get_node(letter_id)
        
        # –ú—è–≥–∫–æ–µ –Ω–∞—á–∞–ª–æ
        session.reply("""
        –ü—Ä–∏–≤–µ—Ç! –ü–æ–º–Ω–∏—Ç–µ, –Ω–µ–¥–µ–ª—é –Ω–∞–∑–∞–¥ –≤—ã –Ω–∞–ø–∏—Å–∞–ª–∏ –ø–∏—Å—å–º–æ —Ä–µ–±–µ–Ω–∫—É?
        
        –Ø —Ö–æ—Ç–µ–ª –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ –Ω–µ–º—É, –µ—Å–ª–∏ –≤—ã –Ω–µ –ø—Ä–æ—Ç–∏–≤.
        """)
        
        # –ß–µ—Ä–µ–∑ –ø–∞—É–∑—É
        time.sleep(2)
        
        session.reply(f"""
        –í–æ—Ç —Ç–æ –ø–∏—Å—å–º–æ:
        
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        {letter['content'][:200]}...
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        
        –¢–æ–≥–¥–∞ —è –≤—ã—Å–∫–∞–∑–∞–ª –æ–ø–∞—Å–µ–Ω–∏—è –ø–æ –ø–æ–≤–æ–¥—É –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫.
        
        –°–µ–π—á–∞—Å, –∫–æ–≥–¥–∞ –ø—Ä–æ—à–ª–æ –≤—Ä–µ–º—è, –∫–∞–∫ –≤—ã —Å–∞–º–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ—Å—å –∫ —ç—Ç–æ–º—É –ø–∏—Å—å–º—É?
        –ú–æ–∂–µ—Ç, —Ö–æ—Ç–∏—Ç–µ —á—Ç–æ-—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å?
        """)
        
        # –î–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤—ã—Å–∫–∞–∑–∞—Ç—å—Å—è
        # ...
        
        session.reply("""
        –ü—Ä–µ–¥–ª–∞–≥–∞—é –≤–º–µ—Å—Ç–µ –µ–≥–æ –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∞—Ç—å. –ù–µ –ø–æ—Ç–æ–º—É —á—Ç–æ –∏—Å—Ö–æ–¥–Ω—ã–π 
        –≤–∞—Ä–∏–∞–Ω—Ç "–ø–ª–æ—Ö–æ–π", –∞ –ø–æ—Ç–æ–º—É —á—Ç–æ –º—ã –º–æ–∂–µ–º —Å–¥–µ–ª–∞—Ç—å –µ–≥–æ –µ—â–µ –±–æ–ª–µ–µ 
        –∏—Å—Ü–µ–ª—è—é—â–∏–º –¥–ª—è —Ä–µ–±–µ–Ω–∫–∞.
        
        –°–æ–≥–ª–∞—Å–Ω—ã?
        """)


# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –±–æ—Ç–∞
@scheduler.daily(hour=19)  # –í–µ—á–µ—Ä–æ–º, –∫–æ–≥–¥–∞ —Å–ø–æ–∫–æ–π–Ω–µ–µ
def run_followup_check():
    """–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ follow-ups"""
    
    active_users = get_active_users()
    followup_manager = FollowUpManager(kag)
    
    for user_id in active_users:
        due_followups = followup_manager.check_due_followups(user_id)
        
        if due_followups:
            # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –º—è–≥–∫–æ–µ –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ
            send_message(user_id, """
            üëã –ü—Ä–∏–≤–µ—Ç! –ï—Å—Ç—å –ø–∞—Ä–∞ –º–æ–º–µ–Ω—Ç–æ–≤, –æ –∫–æ—Ç–æ—Ä—ã—Ö —Ö–æ—Ç–µ–ª –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å.
            –ö–æ–≥–¥–∞ –±—É–¥–µ—Ç —É–¥–æ–±–Ω–æ?
            """)
            
            # –ö–æ–≥–¥–∞ –æ—Ç–≤–µ—Ç–∏—Ç, –∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞—Ç—å follow-up
            # ...
```

---

## üîß –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π

### **1. Inline –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤ Telegram**

```python
@therapy_agent.command("/check")
def check_message_interface(session):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π"""
    
    session.reply("""
    ‚úâÔ∏è –ü–†–û–í–ï–†–ö–ê –°–û–û–ë–©–ï–ù–ò–ô
    
    –Ø –ø–æ–º–æ–≥—É –≤–∞–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π.
    
    –ß—Ç–æ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å?
    1. üì§ –ú–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±—ã–≤—à–µ–º—É –ø–∞—Ä—Ç–Ω–µ—Ä—É
    2. üì• –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –±—ã–≤—à–µ–≥–æ –ø–∞—Ä—Ç–Ω–µ—Ä–∞ (–∞–Ω–∞–ª–∏–∑)
    3. üíå –ü–∏—Å—å–º–æ —Ä–µ–±–µ–Ω–∫—É
    """)
    
    return check_mode_select_state

@check_mode_select_state.body
def select_check_mode(session):
    choice = session.message
    
    if "–±—ã–≤—à–µ–º—É" in choice or choice == "1":
        session.reply("""
        –ù–∞–ø–∏—à–∏—Ç–µ –∏–ª–∏ –ø–µ—Ä–µ—à–ª–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å 
        –±—ã–≤—à–µ–º—É –ø–∞—Ä—Ç–Ω–µ—Ä—É. –Ø –ø—Ä–æ–≤–µ—Ä—é –µ–≥–æ –Ω–∞:
        
        ‚Ä¢ –¢–æ–Ω –∏ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å
        ‚Ä¢ –ú–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏
        ‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ BIFF-–ø—Ä–∏–Ω—Ü–∏–ø–∞–º
        ‚Ä¢ –†–∏—Å–∫ —ç—Å–∫–∞–ª–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞
        
        –ê –∑–∞—Ç–µ–º –ø—Ä–µ–¥–ª–æ–∂—É —É–ª—É—á—à–µ–Ω–∏—è, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.
        """)
        session.memory.set("check_mode", "outgoing_to_ex")
        return analyze_message_state
        
    elif "–æ—Ç –±—ã–≤—à–µ–≥–æ" in choice or choice == "2":
        session.reply("""
        –ü–µ—Ä–µ—à–ª–∏—Ç–µ –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –≤–∞—à–µ–≥–æ –±—ã–≤—à–µ–≥–æ –ø–∞—Ä—Ç–Ω–µ—Ä–∞.
        
        –Ø –ø–æ–º–æ–≥—É –≤–∞–º:
        ‚Ä¢ –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏
        ‚Ä¢ –ü–æ–Ω—è—Ç—å —Å–∫—Ä—ã—Ç—ã–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        ‚Ä¢ –í—ã—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ—Ç–≤–µ—Ç–∞
        ‚Ä¢ –ù–µ –ø–æ–ø–∞—Å—Ç—å –≤ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –ª–æ–≤—É—à–∫—É
        """)
        session.memory.set("check_mode", "incoming_from_ex")
        return analyze_message_state
        
    elif "—Ä–µ–±–µ–Ω–∫—É" in choice or choice == "3":
        # –£–∂–µ –µ—Å—Ç—å –≤ workflow –Ω–∞–ø–∏—Å–∞–Ω–∏—è –ø–∏—Å—å–º–∞
        pass


@analyze_message_state.body
def analyze_and_respond(session):
    """–ê–Ω–∞–ª–∏–∑ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
    
    message_text = session.message
    check_mode = session.memory.get("check_mode")
    guardian = ContentGuardianAgent()
    
    if check_mode == "outgoing_to_ex":
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –±—ã–≤—à–µ–º—É
        review = guardian.review_message_to_ex(
            session.user_id,
            message_text
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        response = "üìä –ê–ù–ê–õ–ò–ó –í–ê–®–ï–ì–û –°–û–û–ë–©–ï–ù–ò–Ø\n\n"
        
        # Toxicity
        toxicity = review["analysis"]["toxicity"]
        response += f"üå° –¢–æ–Ω: {get_tone_emoji(toxicity['toxicity_score'])} "
        response += f"({toxicity['severity']})\n"
        
        # BIFF compliance
        biff = review["analysis"]["biff_compliance"]
        response += f"\nüìã BIFF-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:\n"
        for criterion, passed in biff.items():
            response += f"{'‚úÖ' if passed else '‚ùå'} {criterion}\n"
        
        # Escalation risk
        escalation = review["analysis"]["escalation_risk"]
        response += f"\n‚ö†Ô∏è –†–∏—Å–∫ —ç—Å–∫–∞–ª–∞—Ü–∏–∏: {escalation['level']}\n"
        
        if review["intervention"]["level"] != "none":
            response += f"\n{review['intervention']['message']}\n"
            
            # –ü–æ–∫–∞–∑–∞—Ç—å —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
            suggestions = review["rewritten_suggestions"]
            response += f"""
            
            üí° –ü–†–ï–î–õ–û–ñ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø:
            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            {suggestions['biff_version']}
            ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            
            –ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å:
            {chr(10).join(f"‚Ä¢ {change}" for change in suggestions['improvements'])}
            
            –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç—É –≤–µ—Ä—Å–∏—é?
            1. ‚úÖ –î–∞, —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å
            2. ‚úèÔ∏è –î–æ—Ä–∞–±–æ—Ç–∞—Ç—å –≤–º–µ—Å—Ç–µ
            3. ‚ùå –ù–µ—Ç, –æ—Ç–ø—Ä–∞–≤–ª—é —Å–≤–æ—é
            """
        
        session.reply(response)
        
    elif check_mode == "incoming_from_ex":
        # –ê–Ω–∞–ª–∏–∑ –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        analysis = guardian.analyze_incoming_message(
            session.user_id,
            message_text
        )
        
        response = "üîç –ê–ù–ê–õ–ò–ó –°–û–û–ë–©–ï–ù–ò–Ø –û–¢ –ë–´–í–®–ï–ì–û –ü–ê–†–¢–ù–ï–†–ê\n\n"
        
        # Toxicity
        toxicity = analysis["analysis"]["toxicity"]
        response += f"üå° –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å: {toxicity['severity']}\n"
        
        # Manipulation tactics
        manipulation = analysis["analysis"]["manipulation"]
        if manipulation["has_manipulation"]:
            response += f"\n‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ú–ê–ù–ò–ü–£–õ–Ø–¶–ò–ò:\n\n"
            response += analysis["breakdown"]["explanation"]
            response += "\n\n"
            
            for tactic in manipulation["types"]:
                response += f"üé≠ {tactic}:\n"
                response += f"   {get_tactic_explanation(tactic)}\n\n"
        
        # Response guidance
        guidance = analysis["response_guidance"]
        response += f"""
        
        üí° –ö–ê–ö –û–¢–í–ï–¢–ò–¢–¨:
        
        {guidance['strategy']}
        
        –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        {guidance['suggested_response']}
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        
        –•–æ—Ç–∏—Ç–µ:
        1. üìã –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
        2. ‚úèÔ∏è –ù–∞–ø–∏—Å–∞—Ç—å —Å–≤–æ–π —Å –º–æ–µ–π –ø–æ–º–æ—â—å—é
        3. üö´ –ù–µ –æ—Ç–≤–µ—á–∞—Ç—å (–∏–Ω–æ–≥–¥–∞ —ç—Ç–æ –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç)
        """
        
        session.reply(response)
```

### **2. Web Dashboard (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)**

–î–ª—è –±–æ–ª–µ–µ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –º–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å mini-app:

```javascript
// React –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π

function MessageChecker() {
  const [message, setMessage] = useState('');
  const [analysis, setAnalysis] = useState(null);
  const [mode, setMode] = useState('outgoing'); // outgoing / incoming
  
  const analyzeMessage = async () => {
    const response = await fetch('/api/guardian/analyze', {
      method: 'POST',
      body: JSON.stringify({ message, mode })
    });
    const result = await response.json();
    setAnalysis(result);
  };
  
  return (
    <div className="message-checker">
      <div className="mode-selector">
        <button onClick={() => setMode('outgoing')}>
          –ú–æ—ë —Å–æ–æ–±—â–µ–Ω–∏–µ –±—ã–≤—à–µ–º—É
        </button>
        <button onClick={() => setMode('incoming')}>
          –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –±—ã–≤—à–µ–≥–æ
        </button>
      </div>
      
      <textarea 
        value={message}
        onChange={(e) => setMessage(e.target.value)}
        placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞..."
      />
      
      <button onClick={analyzeMessage}>
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
      </button>
      
      {analysis && (
        <AnalysisResults 
          data={analysis} 
          mode={mode}
        />
      )}
    </div>
  );
}

function AnalysisResults({ data, mode }) {
  return (
    <div className="analysis-results">
      {/* Toxicity meter */}
      <ToxicityMeter score={data.toxicity.score} />
      
      {/* Flags */}
      <FlagsList flags={data.flags} />
      
      {/* Suggestions */}
      {data.suggestions && (
        <div className="suggestions">
          <h3>üí° –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è</h3>
          <ComparisonView 
            original={data.original}
            suggested={data.suggestions.rewritten}
            changes={data.suggestions.changes}
          />
        </div>
      )}
      
      {/* Manipulation breakdown (for incoming) */}
      {mode === 'incoming' && data.manipulation && (
        <ManipulationBreakdown data={data.manipulation} />
      )}
    </div>
  );
}
```

---

## üìä Pattern Tracking –≤ KAG

```python
# –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

kag.query(f"""
MATCH (u:User {{id: '{user_id}'}})-[:WROTE]->(l:Letter)
-[:HAD_REVIEW]->(r:GuardianReview)
WHERE r.date > date('2024-01-01')
RETURN 
  r.date,
  r.toxicity_score,
  r.issues_found,
  r.user_accepted_suggestions
ORDER BY r.date
""")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
def show_progress_chart(session):
    user_id = session.user_id
    
    # –ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–≤–µ—Ä–æ–∫
    reviews = kag.get_user_review_history(user_id)
    
    # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫
    chart = create_progress_chart(reviews)
    
    session.reply(f"""
    üìà –í–ê–® –ü–†–û–ì–†–ï–°–°
    
    –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –º–µ—Å—è—Ü–∞:
    
    {chart}
    
    ‚úÖ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:
    ‚Ä¢ –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å —Å–Ω–∏–∑–∏–ª–∞—Å—å –Ω–∞ 60%
    ‚Ä¢ –í—ã —Å—Ç–∞–ª–∏ —á–∞—â–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    ‚Ä¢ –í –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –ø–∏—Å—å–º–∞—Ö –Ω–µ –±—ã–ª–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥—Ä—É–≥–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è
    
    –≠—Ç–æ –æ–≥—Ä–æ–º–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å! –í—ã —É—á–∏—Ç–µ—Å—å –ø–∏—Å–∞—Ç—å –∏—Å—Ü–µ–ª—è—é—â–µ.
    """)
```

---

## ‚úÖ –ò—Ç–æ–≥–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**

```
BESSER Agent (Workflow) 
    ‚Üì
Content Guardian Agent (Analysis)
    ‚îú‚Üí Toxicity Analyzer (Detoxify + Rules)
    ‚îú‚Üí Manipulation Detector (Patterns + LLM)
    ‚îú‚Üí Child Safety Validator (LLM holistic)
    ‚îî‚Üí BIFF Checker
    ‚Üì
HITL Decision Point (Soft Intervention)
    ‚Üì
KAG (Pattern Tracking + Follow-ups)
```

**–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å:**
- Telegram inline –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
- Mini-app –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ dashboard (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ follow-ups —á–µ—Ä–µ–∑ –±–æ—Ç–∞

**–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:**
1. ‚úÖ **–ù–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å** ‚Äî –≤—Å–µ–≥–¥–∞ –¥–∞–≤–∞—Ç—å –≤—ã–±–æ—Ä
2. üìö **–û–±—É—á–∞—Ç—å** ‚Äî –æ–±—ä—è—Å–Ω—è—Ç—å –ø–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–±–ª–µ–º–∞
3. üí° **–ü—Ä–µ–¥–ª–∞–≥–∞—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã** ‚Äî –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ rewrites
4. üîÑ **–í–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è** ‚Äî follow-up –∫ –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º warning
5. üìà **–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å** ‚Äî –º–æ—Ç–∏–≤–∞—Ü–∏—è —á–µ—Ä–µ–∑ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Ä–æ—Å—Ç–∞

–ù—É–∂–Ω–∞ –¥–µ—Ç–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∫–æ–≥–æ-—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞? –ù–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª–Ω—ã–π –∫–æ–¥ ManipulationDetector –∏–ª–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å follow-up conversation?