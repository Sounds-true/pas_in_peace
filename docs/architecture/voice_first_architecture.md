# Voice-First Architecture
**–ì–æ–ª–æ—Å–æ–≤–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–ø–æ—Å–æ–± –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è**

> üé§ –§–∏–ª–æ—Å–æ—Ñ–∏—è: –ì–æ–≤–æ—Ä–∏—Ç—å –ø—Ä–æ—â–µ, —á–µ–º –ø–µ—á–∞—Ç–∞—Ç—å. –°–ª—É—à–∞—Ç—å –ø—Ä–∏—è—Ç–Ω–µ–µ, —á–µ–º —á–∏—Ç–∞—Ç—å.

---

## üéØ –ö–æ–Ω—Ü–µ–ø—Ü–∏—è

### Voice-First –æ–∑–Ω–∞—á–∞–µ—Ç:

‚úÖ **–ú–∏–∫—Ä–æ—Ñ–æ–Ω - –ø–µ—Ä–≤–æ–µ, —á—Ç–æ –≤–∏–¥–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å**
‚úÖ **–ê–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ª–Ω—ã –ø—Ä–∏–≥–ª–∞—à–∞—é—Ç –≥–æ–≤–æ—Ä–∏—Ç—å**
‚úÖ **–¢–µ–∫—Å—Ç–æ–≤—ã–π –≤–≤–æ–¥ - –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç** (–µ—Å–ª–∏ –Ω–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è / –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)
‚úÖ **–û–∑–≤—É—á–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–µ–Ω–∞** (–º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å –∫–Ω–æ–ø–∫–æ–π)
‚úÖ **–ì–æ–ª–æ—Å–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã everywhere**

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –°–∏—Å—Ç–µ–º—ã

### –£—Ä–æ–≤–Ω–∏ Voice Interaction

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User Interface Layer               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Voice Button (Primary)     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + Animated Waves           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + Permission Request       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Text Input (Fallback)      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + Mic Icon (always)        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Voice Processing Layer             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ STT (üé§‚Üíüìù) ‚îÇ TTS (üìù‚Üíüîä)   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ            ‚îÇ                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Web Speech ‚îÇ Web Speech     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ API        ‚îÇ API            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ     OR     ‚îÇ     OR         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Whisper    ‚îÇ ElevenLabs     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ (OpenAI)   ‚îÇ                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  AI Processing Layer                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  GPT-4 / Claude             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + Quest Builder            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + Content Moderator        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + Multi-Track Manager      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Storage Layer                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + Voice Message URLs       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + Audio Transcripts        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  + TTS Cache                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üé§ Voice Button Component (–≥–ª–∞–≤–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç)

### Design Spec

```tsx
interface VoiceButtonProps {
  isRecording: boolean;
  isProcessing: boolean;
  onStart: () => void;
  onStop: () => void;
  permission: 'granted' | 'denied' | 'prompt';
  waveAnimation?: boolean;
}

const VoiceButton: React.FC<VoiceButtonProps> = ({
  isRecording,
  isProcessing,
  onStart,
  onStop,
  permission,
  waveAnimation = true
}) => {
  return (
    <div className="voice-button-container">
      {/* –ê–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ª–Ω—ã –≤–æ–∫—Ä—É–≥ */}
      {waveAnimation && isRecording && (
        <WaveAnimation />
      )}

      {/* –û—Å–Ω–æ–≤–Ω–∞—è –∫–Ω–æ–ø–∫–∞ */}
      <button
        className={`voice-button ${isRecording ? 'recording' : ''} ${isProcessing ? 'processing' : ''}`}
        onClick={isRecording ? onStop : onStart}
        disabled={permission === 'denied' || isProcessing}
      >
        {isProcessing ? (
          <LoadingSpinner />
        ) : isRecording ? (
          <StopIcon size={32} color="var(--accent-error)" />
        ) : (
          <MicrophoneIcon size={32} color="var(--accent-primary)" />
        )}
      </button>

      {/* Permission request tooltip */}
      {permission === 'prompt' && !isRecording && (
        <Tooltip>
          –ù–∞–∂–º–∏—Ç–µ –∏ —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
        </Tooltip>
      )}

      {/* Error state */}
      {permission === 'denied' && (
        <ErrorMessage>
          –ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±—Ä–∞—É–∑–µ—Ä–∞.
        </ErrorMessage>
      )}
    </div>
  );
};
```

### Wave Animation Component

```tsx
const WaveAnimation: React.FC = () => {
  return (
    <div className="wave-animation">
      {/* –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫—Ä—É–≥–∏ */}
      <div className="wave-ring wave-ring-1" />
      <div className="wave-ring wave-ring-2" />
      <div className="wave-ring wave-ring-3" />

      {/* –ü—É–ª—å—Å–∏—Ä—É—é—â–µ–µ —Å–≤–µ—á–µ–Ω–∏–µ */}
      <div className="wave-glow" />
    </div>
  );
};
```

```css
/* –ê–Ω–∏–º–∞—Ü–∏—è –≤–æ–ª–Ω */
.wave-ring {
  position: absolute;
  width: 100%;
  height: 100%;
  border: 2px solid var(--accent-primary);
  border-radius: 50%;
  opacity: 0;
  animation: wave-expand 2s ease-out infinite;
}

.wave-ring-2 {
  animation-delay: 0.6s;
}

.wave-ring-3 {
  animation-delay: 1.2s;
}

@keyframes wave-expand {
  0% {
    transform: scale(1);
    opacity: 0.6;
  }
  100% {
    transform: scale(2.5);
    opacity: 0;
  }
}

/* –ü—É–ª—å—Å–∏—Ä—É—é—â–µ–µ —Å–≤–µ—á–µ–Ω–∏–µ */
.wave-glow {
  position: absolute;
  width: 100%;
  height: 100%;
  border-radius: 50%;
  background: radial-gradient(
    circle,
    rgba(0, 122, 255, 0.3) 0%,
    transparent 70%
  );
  animation: glow-pulse 1.5s ease-in-out infinite;
}

@keyframes glow-pulse {
  0%, 100% {
    transform: scale(1);
    opacity: 0.5;
  }
  50% {
    transform: scale(1.1);
    opacity: 0.8;
  }
}
```

---

## üîä Speech-to-Text (STT)

### Web Speech API (–æ—Å–Ω–æ–≤–Ω–æ–π)

```typescript
class VoiceST

T {
  private recognition: SpeechRecognition | null = null;
  private isListening = false;

  constructor(
    private language: string = 'ru-RU',
    private onResult: (text: string) => void,
    private onError: (error: string) => void
  ) {
    this.initRecognition();
  }

  private initRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      this.onError('Speech Recognition –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º –±—Ä–∞—É–∑–µ—Ä–µ');
      return;
    }

    this.recognition = new SpeechRecognition();
    this.recognition.lang = this.language;
    this.recognition.continuous = false; // –û–¥–Ω–æ –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏–µ
    this.recognition.interimResults = true; // –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

    this.recognition.onresult = (event) => {
      const transcript = Array.from(event.results)
        .map(result => result[0].transcript)
        .join('');

      // –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
      if (event.results[event.results.length - 1].isFinal) {
        this.onResult(transcript);
      }
    };

    this.recognition.onerror = (event) => {
      this.onError(event.error);
    };

    this.recognition.onend = () => {
      this.isListening = false;
    };
  }

  start() {
    if (!this.recognition) {
      this.onError('Recognition –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
      return;
    }

    if (this.isListening) return;

    try {
      this.recognition.start();
      this.isListening = true;
    } catch (error) {
      this.onError('–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è');
    }
  }

  stop() {
    if (!this.recognition || !this.isListening) return;

    this.recognition.stop();
    this.isListening = false;
  }
}
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```tsx
const [transcript, setTranscript] = useState('');

const voiceSTT = new VoiceSTT(
  'ru-RU',
  (text) => setTranscript(text),
  (error) => console.error(error)
);

// –í –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–µ
<VoiceButton
  onStart={() => voiceSTT.start()}
  onStop={() => voiceSTT.stop()}
/>
```

### Whisper API (fallback –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏)

```typescript
async function transcribeWithWhisper(audioBlob: Blob): Promise<string> {
  const formData = new FormData();
  formData.append('file', audioBlob, 'audio.wav');
  formData.append('model', 'whisper-1');
  formData.append('language', 'ru');

  const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
    },
    body: formData
  });

  const data = await response.json();
  return data.text;
}
```

---

## üì¢ Text-to-Speech (TTS)

### Web Speech API (–æ—Å–Ω–æ–≤–Ω–æ–π)

```typescript
class VoiceTTS {
  private synth = window.speechSynthesis;
  private voice: SpeechSynthesisVoice | null = null;

  constructor(private language: string = 'ru-RU') {
    this.loadVoice();
  }

  private loadVoice() {
    const voices = this.synth.getVoices();
    // –ò—â–µ–º —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å
    this.voice = voices.find(v => v.lang === this.language) || voices[0];
  }

  speak(text: string, options?: {
    rate?: number;   // 0.1 - 10 (1 = normal)
    pitch?: number;  // 0 - 2 (1 = normal)
    volume?: number; // 0 - 1 (1 = max)
  }) {
    if (!this.synth) return;

    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ
    this.synth.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.voice = this.voice;
    utterance.lang = this.language;
    utterance.rate = options?.rate ?? 1;
    utterance.pitch = options?.pitch ?? 1;
    utterance.volume = options?.volume ?? 1;

    this.synth.speak(utterance);
  }

  stop() {
    this.synth.cancel();
  }
}
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```tsx
const tts = new VoiceTTS('ru-RU');

// –û–∑–≤—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç AI
useEffect(() => {
  if (aiResponse && autoPlayAudio) {
    tts.speak(aiResponse);
  }
}, [aiResponse]);

// –ö–Ω–æ–ø–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –æ–∑–≤—É—á–∫–∏
<button onClick={() => setAutoPlayAudio(!autoPlayAudio)}>
  {autoPlayAudio ? <SpeakerOnIcon /> : <SpeakerOffIcon />}
</button>
```

### ElevenLabs (–ø—Ä–µ–º–∏—É–º –æ–∑–≤—É—á–∫–∞)

```typescript
async function generateElevenLabsAudio(text: string): Promise<ArrayBuffer> {
  const response = await fetch('https://api.elevenlabs.io/v1/text-to-speech/voice_id', {
    method: 'POST',
    headers: {
      'Accept': 'audio/mpeg',
      'Content-Type': 'application/json',
      'xi-api-key': process.env.ELEVENLABS_API_KEY
    },
    body: JSON.stringify({
      text,
      model_id: 'eleven_multilingual_v2',
      voice_settings: {
        stability: 0.5,
        similarity_boost: 0.75
      }
    })
  });

  return response.arrayBuffer();
}

// –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏–µ
function playAudio(audioData: ArrayBuffer) {
  const audioContext = new AudioContext();
  audioContext.decodeAudioData(audioData, (buffer) => {
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    source.connect(audioContext.destination);
    source.start(0);
  });
}
```

---

## üéÆ Voice Commands (–≥–æ–ª–æ—Å–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã)

### Command Parser

```typescript
interface VoiceCommand {
  phrases: string[];  // –í–∞—Ä–∏–∞–Ω—Ç—ã —Ñ—Ä–∞–∑
  action: () => void; // –ß—Ç–æ –¥–µ–ª–∞—Ç—å
  description: string; // –î–ª—è help
}

const voiceCommands: VoiceCommand[] = [
  {
    phrases: ['—Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å', '–¥–∞–ª–µ–µ', 'next'],
    action: () => goToNextNode(),
    description: '–ü–µ—Ä–µ–π—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –∑–∞–¥–∞–Ω–∏—é'
  },
  {
    phrases: ['–ø–æ–≤—Ç–æ—Ä–∏', '–µ—â–µ —Ä–∞–∑', 'repeat'],
    action: () => repeatLastMessage(),
    description: '–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ'
  },
  {
    phrases: ['–ø–æ–¥—Å–∫–∞–∑–∫–∞', '–ø–æ–º–æ—â—å', 'hint'],
    action: () => showHint(),
    description: '–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫—É'
  },
  {
    phrases: ['–ø–æ–∫–∞–∂–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å', '–º–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å', 'progress'],
    action: () => showProgress(),
    description: '–ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å'
  },
  {
    phrases: ['—Å—Ç–æ–ø', '–ø–∞—É–∑–∞', 'stop'],
    action: () => pauseQuest(),
    description: '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–≤–µ—Å—Ç'
  }
];

function parseVoiceCommand(text: string): VoiceCommand | null {
  const normalizedText = text.toLowerCase().trim();

  for (const command of voiceCommands) {
    if (command.phrases.some(phrase => normalizedText.includes(phrase))) {
      return command;
    }
  }

  return null;
}
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```tsx
const handleVoiceInput = (text: string) => {
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –∏–ª–∏ –æ–±—ã—á–Ω—ã–π –≤–≤–æ–¥
  const command = parseVoiceCommand(text);

  if (command) {
    command.action();
    tts.speak(`–í—ã–ø–æ–ª–Ω—è—é: ${command.description}`);
  } else {
    // –û–±—ã—á–Ω—ã–π –≤–≤–æ–¥ - –ø–µ—Ä–µ–¥–∞–µ–º –≤ AI
    processUserMessage(text);
  }
};
```

---

## üß© –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Quest Builder

### Voice-Driven Quest Creation

```tsx
const QuestBuilderVoice: React.FC = () => {
  const [stage, setStage] = useState<QuestStage>('INITIAL');
  const [context, setContext] = useState<QuestContext>({});
  const [isListening, setIsListening] = useState(false);

  const handleVoiceInput = async (transcript: string) => {
    // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ AI
    const response = await questBuilderAI.processInput(transcript, context);

    // –û–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
    tts.speak(response.message);

    // –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    setContext(response.updatedContext);
    setStage(response.nextStage);
  };

  return (
    <div className="glass-card p-8">
      {/* AI Avatar (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) */}
      <AIAvatar isThinking={isProcessing} />

      {/* –ì–ª–∞–≤–Ω–∞—è –∫–Ω–æ–ø–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ */}
      <VoiceButton
        isRecording={isListening}
        onStart={() => {
          setIsListening(true);
          voiceSTT.start();
        }}
        onStop={() => {
          setIsListening(false);
          voiceSTT.stop();
        }}
      />

      {/* –¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å AI (—Ç–µ–∫—Å—Ç + –æ–∑–≤—É—á–∫–∞) */}
      <div className="mt-6 text-center">
        <p className="body-secondary">
          {getCurrentQuestion(stage)}
        </p>
      </div>

      {/* Transcript (—á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–∞–∑–∞–ª) */}
      {transcript && (
        <div className="mt-4 glass-card p-4 bg-accent-primary-soft">
          <p className="caption">–í—ã —Å–∫–∞–∑–∞–ª–∏:</p>
          <p className="body">{transcript}</p>
        </div>
      )}

      {/* Fallback - —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤–≤–æ–¥ */}
      <button
        className="mt-4 text-accent-primary caption"
        onClick={() => setShowTextInput(true)}
      >
        –ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º
      </button>

      {showTextInput && (
        <div className="mt-4 animate-slide-up">
          <div className="glass-input-with-voice">
            <input
              className="glass-input"
              placeholder="–í–≤–µ–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç..."
              onKeyPress={(e) => {
                if (e.key === 'Enter') {
                  handleVoiceInput(e.currentTarget.value);
                }
              }}
            />
            <MicIcon
              className="glass-input-voice-icon"
              onClick={() => setShowTextInput(false)}
            />
          </div>
        </div>
      )}
    </div>
  );
};
```

---

## üéØ Child Quest Player (Voice Mode)

### Voice-Enabled Quest Gameplay

```tsx
const QuestPlayerVoice: React.FC<{quest: Quest}> = ({quest}) => {
  const [currentNode, setCurrentNode] = useState(quest.nodes[0]);
  const [isListening, setIsListening] = useState(false);

  // –û–∑–≤—É—á–∏–≤–∞–µ–º –∑–∞–¥–∞–Ω–∏–µ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–æ–¥—ã
  useEffect(() => {
    if (autoPlayAudio) {
      tts.speak(currentNode.challenge);
    }
  }, [currentNode]);

  const handleVoiceAnswer = async (answer: string) => {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
    const isCorrect = checkAnswer(answer, currentNode.answer);

    if (isCorrect) {
      tts.speak('–ü—Ä–∞–≤–∏–ª—å–Ω–æ! –û—Ç–ª–∏—á–Ω–æ!');
      // Reveal –º–æ–º–µ–Ω—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
      if (currentNode.reveal) {
        setTimeout(() => {
          tts.speak(currentNode.reveal.message);
        }, 1000);
      }
      // –°–ª–µ–¥—É—é—â–∞—è –Ω–æ–¥–∞
      setCurrentNode(quest.nodes[currentNode.id + 1]);
    } else {
      tts.speak('–ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑');
    }
  };

  return (
    <div className="glass-card p-8">
      {/* Quest Header */}
      <h2 className="heading-2 text-center mb-6">
        {quest.title}
      </h2>

      {/* Current Challenge */}
      <div className="glass-card p-6 bg-glass-blue mb-6">
        <p className="body text-center">
          {currentNode.challenge}
        </p>

        {/* –ö–Ω–æ–ø–∫–∞ "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å" */}
        <button
          className="glass-button mt-4 w-full"
          onClick={() => tts.speak(currentNode.challenge)}
        >
          üîä –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–¥–∞–Ω–∏–µ
        </button>
      </div>

      {/* Voice Input */}
      <VoiceButton
        isRecording={isListening}
        onStart={() => {
          setIsListening(true);
          voiceSTT.start();
        }}
        onStop={() => {
          setIsListening(false);
          voiceSTT.stop();
        }}
      />

      <p className="caption text-center mt-4">
        –°–∫–∞–∂–∏ –æ—Ç–≤–µ—Ç –≤—Å–ª—É—Ö
      </p>

      {/* Progress */}
      <div className="mt-8">
        <div className="glass-progress">
          <div
            className="glass-progress-fill"
            style={{width: `${(currentNode.id / quest.nodes.length) * 100}%`}}
          />
        </div>
        <p className="caption text-center mt-2">
          –ó–∞–¥–∞–Ω–∏–µ {currentNode.id + 1} –∏–∑ {quest.nodes.length}
        </p>
      </div>
    </div>
  );
};
```

---

## üìä Voice Analytics

### –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```typescript
interface VoiceInteraction {
  id: string;
  user_id: number;
  timestamp: Date;
  transcript: string;
  audio_url?: string;  // –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ
  duration_ms: number;
  language: string;
  confidence: number;  // –û—Ç STT
  intent?: string;     // –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ–Ω—Ç
  command_used?: string;
}

// –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
async function saveVoiceInteraction(
  userId: number,
  transcript: string,
  audioBlob?: Blob
): Promise<void> {
  let audioUrl = null;

  // –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞—É–¥–∏–æ (–¥–ª—è —Ä–µ–≤—å—é –ø—Å–∏—Ö–æ–ª–æ–≥–∞)
  if (audioBlob) {
    audioUrl = await uploadToS3(audioBlob);
  }

  await db.voiceInteractions.create({
    user_id: userId,
    transcript,
    audio_url: audioUrl,
    duration_ms: audioBlob?.size ? calculateDuration(audioBlob) : 0,
    language: 'ru-RU',
    confidence: 0.95, // –û—Ç STT
  });
}
```

---

## üîí Privacy & Permissions

### Permission Flow

```tsx
const VoicePermissionRequest: React.FC = () => {
  const [permission, setPermission] = useState<PermissionState>('prompt');

  const requestPermission = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({audio: true});

      // –£—Å–ø–µ—Ö
      setPermission('granted');

      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º stream (–æ–Ω –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω)
      stream.getTracks().forEach(track => track.stop());

    } catch (error) {
      // –û—Ç–∫–∞–∑
      setPermission('denied');
    }
  };

  if (permission === 'granted') {
    return <VoiceButton />;
  }

  return (
    <div className="glass-card p-8 text-center">
      <MicrophoneIcon size={64} className="mx-auto mb-4 text-accent-primary opacity-50" />

      <h3 className="heading-3 mb-2">
        –†–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
      </h3>

      <p className="body-secondary mb-6">
        –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –≤–∞–º –æ–±—â–∞—Ç—å—Å—è –≥–æ–ª–æ—Å–æ–º.
        –ú—ã –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ–º –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ.
      </p>

      <button
        className="glass-button-primary"
        onClick={requestPermission}
      >
        –†–∞–∑—Ä–µ—à–∏—Ç—å
      </button>

      <button
        className="glass-button mt-2"
        onClick={() => setShowTextInput(true)}
      >
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç
      </button>
    </div>
  );
};
```

---

## üöÄ Implementation Roadmap

### Week 1: Core Voice Components
- [ ] VoiceButton with wave animation
- [ ] Web Speech API integration (STT/TTS)
- [ ] Permission handling
- [ ] Basic voice commands

### Week 2: Quest Builder Voice
- [ ] Voice-driven dialogue
- [ ] AI response synthesis
- [ ] Context extraction from speech
- [ ] Fallback to text

### Week 3: Child Player Voice
- [ ] Voice answer checking
- [ ] Audio narration of challenges
- [ ] Voice commands in quests
- [ ] Progress announcements

### Week 4: Advanced Features
- [ ] Whisper API fallback
- [ ] ElevenLabs premium voices
- [ ] Voice analytics
- [ ] Offline mode (cache TTS)

---

## üìù Best Practices

### 1. **Always Provide Fallback**
```tsx
{hasVoiceSupport ? <VoiceButton /> : <TextInput />}
```

### 2. **Show Visual Feedback**
```tsx
{isListening && <WaveAnimation />}
{isProcessing && <LoadingSpinner />}
```

### 3. **Handle Errors Gracefully**
```tsx
if (error === 'not-allowed') {
  showMessage('–†–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö');
}
```

### 4. **Cache TTS for Performance**
```typescript
const ttsCache = new Map<string, AudioBuffer>();

async function speakCached(text: string) {
  if (ttsCache.has(text)) {
    playFromCache(text);
  } else {
    const audio = await generateTTS(text);
    ttsCache.set(text, audio);
    playAudio(audio);
  }
}
```

### 5. **Respect User Preferences**
```tsx
const [autoPlay, setAutoPlay] = useLocalStorage('autoplay_audio', true);
const [voiceEnabled, setVoiceEnabled] = useLocalStorage('voice_enabled', true);
```

---

**Status**: üöÄ Ready for Implementation
**Priority**: HIGH (–æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª)
**Estimated Time**: 4 weeks
